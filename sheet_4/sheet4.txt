Theory:
1.1: No, it's feature-based.
1.2: Yes.
1.3: No, LIME is local.
1.4: No.

2.1: Yes.
2.2: No.
2.3: Yes.
2.4: Yes. Not sure what's meant by "local explanation vector/ matrix".

3.1: Yes.
3.2: Yes.
3.3: No.
3.4: It doesn't delete them, it switches them for knock-off features, which preserve the distribution.
     If that's meant by deleting then yes.

4.1: No, not globally relevant, a saliency map is always just a computed for one specific input.
4.2: Yes.
4.3: I would not say they would be used for that primarily. But looking at a counterfactual explanation
     could help you understand, why another input was classified the way it was, which might be 
     helpful in a justifying context.
4.4: No.

5.1: Not any linear model, no.
5.2: No, they don't have to, it's one way of evaluation.
5.3: No.
5.4: Yes.
